{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# MNIST"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "# 데이터 불러오기\r\n",
    "train_data = np.loadtxt(\"C:/Users/user/Desktop/work/Deep-Learning-from-Scratch/Chapter_3/mnist_train.csv\", delimiter=',', dtype=np.float32)\r\n",
    "test_data = np.loadtxt(\"C:/Users/user/Desktop/work/Deep-Learning-from-Scratch/Chapter_3/mnist_test.csv\", delimiter=',', dtype=np.float32)\r\n",
    "\r\n",
    "print(train_data.shape, test_data.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60000, 785) (10000, 785)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "input_train_data = train_data[:, 1:]\r\n",
    "target_train_data = train_data[:, 0]\r\n",
    "input_test_data = test_data[:, 1:]\r\n",
    "target_test_data = test_data[:, 0]\r\n",
    "\r\n",
    "print(input_train_data.shape, target_train_data.shape, input_test_data.shape, target_test_data.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60000, 784) (60000,) (10000, 784) (10000,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 이미지 출력하기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from PIL import Image\r\n",
    "def img_show(img):\r\n",
    "    pil_img = Image.fromarray(np.uint8(img))\r\n",
    "    pil_img.show()\r\n",
    "\r\n",
    "img = input_train_data[0]\r\n",
    "label = target_train_data[0]\r\n",
    "print(label)\r\n",
    "\r\n",
    "img = img.reshape(28, 28)\r\n",
    "img_show(img)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "img = input_train_data[0].reshape(28, 28)\r\n",
    "plt.imshow(img, cmap='gray')\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def sigmoid(x):\r\n",
    "    return 1 / (1 + np.exp(-x))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "def softmax(x):\r\n",
    "    exp_x = np.exp(x)\r\n",
    "    sum_exp_x = np.sum(exp_x)\r\n",
    "    y = exp_x / sum_exp_x\r\n",
    "    return y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def numerical_differentiation(f, x):\r\n",
    "    delta_x = 1e-4\r\n",
    "    grad = np.zeros_like(x)\r\n",
    "    \r\n",
    "    for idx in range(x.size):\r\n",
    "        tmp_val = x[idx]\r\n",
    "\r\n",
    "        x[idx] = tmp_val + delta_x\r\n",
    "        fx1 = f(x)\r\n",
    "\r\n",
    "        x[idx] = tmp_val - delta_x\r\n",
    "        fx2 = f(x)\r\n",
    "\r\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\r\n",
    "        x[idx] = tmp_val\r\n",
    "\r\n",
    "    return grad"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class TwoLayerNet:\r\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate):\r\n",
    "        self.params = {}\r\n",
    "\r\n",
    "        self.params['W1'] = np.random.rand(input_size, hidden_size)\r\n",
    "        self.params['b1'] = np.zeros(hidden_size)\r\n",
    "        self.params['W2'] = np.random.rand(hidden_size, output_size)\r\n",
    "        self.params['b2'] = np.zeros(output_size)\r\n",
    "        self.learning_rate = learning_rate\r\n",
    "\r\n",
    "        print(\"Two Layer Network object is now created!\")\r\n",
    "    \r\n",
    "    def feed_forward(self, x, t):\r\n",
    "        delta = 1e-7\r\n",
    "\r\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\r\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\r\n",
    "\r\n",
    "        Z1 = np.dot(x, W1) + b1\r\n",
    "        A1 = sigmoid(Z1)\r\n",
    "\r\n",
    "        Z2 = np.dot(A1, W2) + b2\r\n",
    "        y = A2 = softmax(Z2)\r\n",
    "        \r\n",
    "        return -np.sum( t*np.log(y+delta) + (1-t)*np.log((1-y)+delta) )\r\n",
    "    \r\n",
    "    def loss_function(self, x, t):\r\n",
    "        delta = 1e-7\r\n",
    "\r\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\r\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\r\n",
    "\r\n",
    "        Z1 = np.dot(x, W1) + b1\r\n",
    "        A1 = sigmoid(Z1)\r\n",
    "\r\n",
    "        Z2 = np.dot(A1, W2) + b2\r\n",
    "        y = A2 = softmax(Z2)\r\n",
    "        \r\n",
    "        return -np.sum( t*np.log(y+delta) + (1-t)*np.log((1-y)+delta) )\r\n",
    "\r\n",
    "    def train(self, x, t):\r\n",
    "        f = lambda x : self.loss_function(x, t)\r\n",
    "\r\n",
    "        self.params['W1'] -= self.learning_rate * numerical_differentiation(f, self.params['W1'])\r\n",
    "        self.params['b1'] -= self.learning_rate * numerical_differentiation(f, self.params['b1'])\r\n",
    "        self.params['W2'] -= self.learning_rate * numerical_differentiation(f, self.params['W2'])\r\n",
    "        self.params['b2'] -= self.learning_rate * numerical_differentiation(f, self.params['b2'])\r\n",
    "\r\n",
    "    def predict(self, x):\r\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\r\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\r\n",
    "\r\n",
    "        Z1 = np.dot(x, W1) + b1\r\n",
    "        A1 = sigmoid(Z1)\r\n",
    "\r\n",
    "        Z2 = np.dot(A1, W2) + b2\r\n",
    "        y = A2 = softmax(Z2)\r\n",
    "\r\n",
    "        predicted_num = np.argmax(y, axis=1)\r\n",
    "\r\n",
    "        return predicted_num\r\n",
    "\r\n",
    "    def accuracy(self, x, t):\r\n",
    "        y = self.predict(x)\r\n",
    "        t = np.argmax(t, axis=1)\r\n",
    "\r\n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\r\n",
    "        return accuracy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from datetime import datetime\r\n",
    "\r\n",
    "net = TwoLayerNet(input_size=784, hidden_size=50, output_size=10, learning_rate=0.01)\r\n",
    "epochs = 1\r\n",
    "train_size = input_train_data.shape[0]\r\n",
    "batch_size = 100\r\n",
    "\r\n",
    "start_time = datetime.now()\r\n",
    "\r\n",
    "for step in range(epochs):\r\n",
    "\r\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\r\n",
    "    input_batch = input_train_data[batch_mask]\r\n",
    "    target_batch = target_train_data[batch_mask]\r\n",
    "\r\n",
    "    for index in range(len(train_data)):\r\n",
    "\r\n",
    "        net.train(input_train_data, target_train_data)\r\n",
    "\r\n",
    "        if(index % 200 == 0):\r\n",
    "            print(\"step = \", step, \"loss value = \", net.loss_function())\r\n",
    "            \r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}